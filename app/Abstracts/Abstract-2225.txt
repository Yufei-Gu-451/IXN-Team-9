Fortification is the process of adding nutrients or non-nutrient bioactive components to edible products (e.g., food, food constituents, or supplements). Fortification can be used to correct or prevent widespread nutrient intake shortfalls and associated deficiencies, to balance the total nutrient profile of a diet, to restore nutrients lost in processing, or to appeal to consumers looking to supplement their diet. Food fortification could be considered as a public health strategy to enhance nutrient intakes of a population. Over the past century, fortification has been effective at reducing the risk of nutrient deficiency diseases such as beriberi, goiter, pellagra, and rickets. However, the world today is very different from when fortification emerged in the 1920s. Although early fortification programs were designed to eliminate deficiency diseases, current fortification programs are based on low dietary intakes rather than a diagnosable condition. Moving forward, we must be diligent in our approach to achieving effective and responsible fortification practices and policies, including responsible marketing of fortified products. Fortification must be applied prudently, its effects monitored diligently, and the public informed effectively about its benefits through consumer education efforts. Clear lines of authority for establishing fortification guidelines should be developed and should take into account changing population demographics, changes in the food supply, and advances in technology. This article is a summary of a symposium presented at the ASN Scientific Sessions and Annual Meeting at Experimental Biology 2014 on current issues involving fortification focusing primarily on the United States and Canada and recommendations for the development of responsible fortification practices to ensure their safety and effectiveness.